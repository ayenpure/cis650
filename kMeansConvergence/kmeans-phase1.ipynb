{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<h1>K-MEANS</h1>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import math\n",
    "import operator\n",
    "from multiprocessing import Pool,current_process,cpu_count,active_children\n",
    "from timeit import default_timer as timer\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.12 (default, Nov 19 2016, 06:48:10) \\n[GCC 5.4.0 20160609]'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.version  # 2.7.13 - if higher version then packages may not work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternative ingest functions\n",
    "\n",
    "Store points in variable `batch` as dictionary. key is point-id (number) and value is the vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total points: 4338\n",
      "First line: (0, [7.52, 1.0, 11.0, 0.0074, 7.0])\n"
     ]
    }
   ],
   "source": [
    "# 5 columns: 7.52\t1\t11\t0.0074\t7\t1\n",
    "# Strip off Unqiue_Key. Produce dict with line numbers as key and 5d vector as value. No empties.\n",
    "def readBoyanaFile(fname):\n",
    "    fid = open(fname,'r')\n",
    "    data = fid.readlines()\n",
    "    l = map(lambda line : map(float, line.rstrip().split())[:-1],data)\n",
    "    return {i:v for i,v in enumerate(l)}\n",
    "\n",
    "# Read in data\n",
    "my_dir = os.path.expanduser(\"./\")\n",
    "my_fname = \"N_combinedLogs_hourly.txt\"\n",
    "batch = readBoyanaFile(my_dir+my_fname) #one big batch as dictionary\n",
    "print('Total points: ' + str(len(batch)) )  # 4338\n",
    "print('First line: {}'.format(batch.items()[0]))  # (0, [7.52, 1.0, 11.0, 0.0074, 7.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-15-5c7c3bfca707>, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-5c7c3bfca707>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    my_dir = os.path.expanduser(\"~/Dropbox/winter650_2017/homework/\")\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "# https://archive.ics.uci.edu/ml/datasets/Individual+household+electric+power+consumption\n",
    "# 9 columns: 16/12/2006;17:24:00;4.216;0.418;234.840;18.400;0.000;1.000;17.000\n",
    "# Strip off first 2 and float others. Skip lines with ? (empties)\n",
    "def readElectricFile(fname):\n",
    "\n",
    "\n",
    "\n",
    "# Read in data\n",
    "my_dir = os.path.expanduser(\"~/Dropbox/winter650_2017/homework/\")\n",
    "my_fname = \"household_power_consumption.txt\"\n",
    "batch = readElectricFile(my_dir+my_fname) #one big batch as dictionary\n",
    "print('Total points: ' + str(len(batch)) )  # 2049280\n",
    "print('First line: {}'.format(batch.items()[0]))  # (0, [4.216, 0.418, 234.84, 18.4, 0.0, 1.0, 17.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose k and starting k centers\n",
    "\n",
    "Google around for different strategies for choosing k and choosing starting center values.\n",
    "\n",
    "But first use my choices to make sure you get the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: [20.0, 5.0, 3.0, 0.0, 0.0],\n",
       " 2: [17.0, 4.0, 8.0, 0.0847, 80.0],\n",
       " 3: [22.0, 3.0, 1.0, 0.5874, 558.0]}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 3\n",
    "\n",
    "blen = len(batch)\n",
    "\n",
    "initial_C = {1: batch[blen/2], 2: batch[blen/3], 3: batch[blen/5]}  # keep this to reset to\n",
    "\n",
    "C = initial_C\n",
    "\n",
    "# Boyana - converged to 0 changes in 25 iterations (total time .76 seconds with 4 core)\n",
    "'''{1: [20.0, 5.0, 3.0, 0.0, 0.0],\n",
    "    2: [17.0, 4.0, 8.0, 0.0847, 80.0],\n",
    "    3: [22.0, 3.0, 1.0, 0.5874, 558.0]}\n",
    "'''\n",
    "# Electric - converged to 0 changes in 13 iterations (total time 273 seconds with 4 core)\n",
    "'''{1: [1.318, 0.066, 244.14, 5.4, 0.0, 0.0, 19.0],\n",
    "    2: [2.228, 0.072, 240.04, 9.2, 0.0, 0.0, 18.0],\n",
    "    3: [0.384, 0.188, 238.91, 1.8, 0.0, 0.0, 0.0]}\n",
    "'''\n",
    "\n",
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for first phase\n",
    "\n",
    "Assign each point to closest center using euclidean distance.\n",
    "\n",
    "Note possibility of parallelization of summing: https://stackoverflow.com/a/29785751.\n",
    "\n",
    "Probably can use similar strategy for taking minimum. Break into chunks and have each core min its chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thought problem: do we need the sqrt? en.wikipedia.org/wiki/Euclidean_distance#Squared_Euclidean_distance\n",
    "def euclidean_distance(vec1, vec2):\n",
    "    zipped = zip(vec1, vec2)\n",
    "    sqdiff = map(lambda pair: (pair[0] - pair[1])**2, zipped)\n",
    "    summation = sum(sqdiff)\n",
    "    return math.sqrt(summation) #test this function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Given a point tuple, find the closest center. Return its id.\n",
    "def compute_center(point, all_centers):\n",
    "    value = point[1]\n",
    "    centers_list = all_centers.items()\n",
    "    distances = map(lambda pair: (pair[0], euclidean_distance(value, pair[1])), centers_list)\n",
    "    tup = min(distances, key=lambda t: t[1])\n",
    "    return tup[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do a test\n",
    "compute_center(batch.items()[0], C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1 test loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cores available: 8\n",
      "Total cores used: 4\n"
     ]
    }
   ],
   "source": [
    "# number of workers\n",
    "processors = cpu_count()\n",
    "print(\"Total cores available: {}\".format(processors))\n",
    "\n",
    "#N = processors  # change this to experient with different times\n",
    "\n",
    "N = 4\n",
    "print(\"Total cores used: {}\".format(N))\n",
    "\n",
    "# This function called when set up pool of processors. For now, just prints debugging info.\n",
    "def start_process():\n",
    "    #print( 'Starting {} with pid {}'.format(current_process().name,current_process().pid)) #delayed print from when pool initialized\n",
    "    return\n",
    "\n",
    "# Start a pool of N workers\n",
    "pool = Pool(processes=N,\n",
    "            initializer=start_process\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Starting iteration 0\n",
      "time of part 1: 0.0260820388794\n"
     ]
    }
   ],
   "source": [
    "iterations = 1  # just for testing\n",
    "total_time = 0\n",
    "for i in range(iterations):\n",
    "    print(\"========= Starting iteration \" + str(i))\n",
    "\n",
    "\n",
    "    # assign points to centers 2D\n",
    "    start = timer()\n",
    "    partial_compute = partial(compute_center, all_centers = C) #moved this inside loop b/c gets updated after each iteration\n",
    "\n",
    "    new_p_to_c_map = pool.map(partial_compute, batch.items())\n",
    "\n",
    "    end = timer()\n",
    "\n",
    "    t = end - start\n",
    "    total_time += t\n",
    "    print( \"time of part 1: \" + str(t))\n",
    "    \n",
    "pool.close() # no more tasks\n",
    "pool.join()  # wrap up current tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: [11.506257848472165, 5.915027208036835, 8.490581833403098, 0.004166429468396858, 1.8522394307241523], 2: [12.106736111111111, 4.895833333333333, 8.45138888888889, 0.140497619047619, 132.7123015873016], 3: [10.60104144527099, 5.207226354941551, 10.193411264612115, 0.8035047821466521, 762.230605738576]}\n"
     ]
    }
   ],
   "source": [
    "mymap = {}\n",
    "for i,j in zip (new_p_to_c_map, batch.values()):\n",
    "    mymap.setdefault(i, []).append(j)\n",
    "newCenters = {}\n",
    "for i in mymap.keys():\n",
    "    newCenters[i] = map(lambda x: x/len(mymap.get(i)), reduce(lambda first, second : map(operator.add, first,second), mymap.get(i)))\n",
    "print newCenters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for second phase\n",
    "\n",
    "You now have points mapped to centers. In particular, `new_p_to_c_map` is a list of center-ids *e.g., 1,2,3. The value of\n",
    "`new_p_to_c_map[0]` is the center-id that goes with point 0.\n",
    "\n",
    "Now we need to recompute mean for all k centers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your functions go here\n",
    "def recompute_centers(clustermapping, items):\n",
    "    mymap = {}\n",
    "    for i,j in zip (clustermapping, items):\n",
    "        mymap.setdefault(i, []).append(j)\n",
    "    listsToReduce = []\n",
    "    lengthsList = []\n",
    "    for i in mymap.keys():\n",
    "        listsToReduce.append(mymap.get(i))\n",
    "        lengthsList.append(len(mymap.get(i)))\n",
    "    reducedLists = map(reduce(lambda first, second : map(operator.add, first,second)), listsToReduce)\n",
    "    newCenters = enumerate(map(lambda pair : pair[0] / pair[1] , zip (reducedLists, lengthsList))) \n",
    "    return newCenters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ready to start clustering\n",
    "\n",
    "Do set-up first. You can rerun some of these cells to try new experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cores available: 8\n",
      "Total cores used: 4\n"
     ]
    }
   ],
   "source": [
    "# number of workers\n",
    "processors = cpu_count()\n",
    "print(\"Total cores available: {}\".format(processors))\n",
    "\n",
    "#N = processors  # change this to experient with different times\n",
    "\n",
    "N = 4\n",
    "print(\"Total cores used: {}\".format(N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 50\n"
     ]
    }
   ],
   "source": [
    "iterations = 50\n",
    "print(\"Number of iterations: {}\".format(iterations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use this to reset before each new run\n",
    "p_to_c_map = [-1]*len(batch)  # -1 is not a center-id so changes on first iter will be maximum.\n",
    "C = initial_C  # reset C to starting center values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main loop\n",
    "\n",
    "Will stop either after so many interations or when changes to `p_to_c_map` become 0, i.e., no points changed allegiance during the current iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Starting iteration 0\n",
      "time of part 1: 0.0265691280365\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "reduce expected at least 2 arguments, got 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-02d13c298e76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"time of part 1: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mnew_C\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecompute_centers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_p_to_c_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# compute new values of centers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-54-7abf522db3c7>\u001b[0m in \u001b[0;36mrecompute_centers\u001b[0;34m(clustermapping, items)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mlistsToReduce\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmymap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mlengthsList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmymap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mreducedLists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mfirst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecond\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msecond\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlistsToReduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mnewCenters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mpair\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mpair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mpair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mreducedLists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengthsList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnewCenters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: reduce expected at least 2 arguments, got 1"
     ]
    }
   ],
   "source": [
    "# Start a pool of N workers\n",
    "pool = Pool(processes=N,\n",
    "            initializer=start_process,\n",
    "           )\n",
    "\n",
    "total_time = 0\n",
    "for i in range(iterations):\n",
    "    print(\"========= Starting iteration \" + str(i))\n",
    "    \n",
    "    # assign points to centers 2D\n",
    "    start = timer()\n",
    "\n",
    "    partial_compute = partial(compute_center, all_centers = C) #moved this inside loop b/c gets updated after each iteration\n",
    "    new_p_to_c_map = pool.map(partial_compute, batch.items())\n",
    "\n",
    "    end = timer()\n",
    "\n",
    "    t = end - start\n",
    "    total_time += t\n",
    "    print( \"time of part 1: \" + str(t))\n",
    "    start = timer()\n",
    "    new_C = recompute_centers(new_p_to_c_map, batch.values())  # compute new values of centers\n",
    "    end = timer()\n",
    "    t = end - start\n",
    "    total_time += t\n",
    "    print( \"time of part 2: \" + str(t))\n",
    "    for tup in zip(C.values(), new_C.values()):\n",
    "        #print(tup[0])\n",
    "        #print(tup[1])\n",
    "        #print(euclidean_distance(tup[0],tup[1]))\n",
    "        changed_centers = euclidean_distance(tup[0],tup[1])\n",
    "        #print(\"-----------\")\n",
    "    \n",
    "    #changed_centers = 0  # hoping value is 0\n",
    "    print('Changes: {}'.format(changed_centers))\n",
    "\n",
    "    C = new_C  # update centers with new values\n",
    "    p_to_c_map = new_p_to_c_map  #update map\n",
    "    \n",
    "    if changed_centers == 0:\n",
    "          break  # last iteration caused no allegiance changes\n",
    "    \n",
    "pool.close() # no more tasks\n",
    "pool.join()  # wrap up current tasks\n",
    "print(\"Total time: \" + str(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
